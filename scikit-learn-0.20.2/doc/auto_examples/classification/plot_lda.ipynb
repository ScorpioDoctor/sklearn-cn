{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# \u5e94\u7528\u4e8e\u5206\u7c7b\u4efb\u52a1\u7684 \u6b63\u5e38LDA\u548c\u7f29\u51cfLDA\n\n\n\u8fd9\u4e2a\u4f8b\u5b50\u4e3b\u8981\u5c55\u793a\u4e86\u7f29\u51cf(shrinkage)\u662f\u5982\u4f55\u63d0\u5347LDA\u5206\u7c7b\u5668\u7684\u6027\u80fd\u7684\u3002\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from __future__ import division\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.datasets import make_blobs\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n\n\nn_train = 20  # samples for training\nn_test = 200  # samples for testing\nn_averages = 50  # how often to repeat classification\nn_features_max = 75  # maximum number of features\nstep = 4  # step size for the calculation\n\n\ndef generate_data(n_samples, n_features):\n    \"\"\"Generate random blob-ish data with noisy features.\n\n    This returns an array of input data with shape `(n_samples, n_features)`\n    and an array of `n_samples` target labels.\n\n    \u53ea\u6709\u4e00\u4e2a\u7279\u5f81\u5305\u542b\u72ec\u7279\u4fe1\u606f\u6216\u8005\u53eb\u9274\u522b\u4fe1\u606f(discriminative information), \n    \u5269\u4f59\u7684\u6240\u6709\u7279\u5f81\u90fd\u53ea\u542b\u6709\u566a\u58f0\u3002\n    \"\"\"\n    X, y = make_blobs(n_samples=n_samples, n_features=1, centers=[[-2], [2]])\n\n    # add non-discriminative features\n    if n_features > 1:\n        X = np.hstack([X, np.random.randn(n_samples, n_features - 1)])\n    return X, y\n\nacc_clf1, acc_clf2 = [], []\nn_features_range = range(1, n_features_max + 1, step)\nfor n_features in n_features_range:\n    score_clf1, score_clf2 = 0, 0\n    for _ in range(n_averages):\n        X, y = generate_data(n_train, n_features)\n\n        clf1 = LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto').fit(X, y)\n        clf2 = LinearDiscriminantAnalysis(solver='lsqr', shrinkage=None).fit(X, y)\n\n        X, y = generate_data(n_test, n_features)\n        score_clf1 += clf1.score(X, y)\n        score_clf2 += clf2.score(X, y)\n\n    acc_clf1.append(score_clf1 / n_averages)\n    acc_clf2.append(score_clf2 / n_averages)\n\nfeatures_samples_ratio = np.array(n_features_range) / n_train\n\nplt.plot(features_samples_ratio, acc_clf1, linewidth=2,\n         label=\"Linear Discriminant Analysis with shrinkage\", color='navy')\nplt.plot(features_samples_ratio, acc_clf2, linewidth=2,\n         label=\"Linear Discriminant Analysis\", color='gold')\n\nplt.xlabel('n_features / n_samples')\nplt.ylabel('Classification accuracy')\n\nplt.legend(loc=1, prop={'size': 12})\nplt.suptitle('Linear Discriminant Analysis vs. \\\nshrinkage Linear Discriminant Analysis (1 discriminative feature)')\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}