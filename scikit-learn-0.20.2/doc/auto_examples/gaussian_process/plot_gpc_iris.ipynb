{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n=====================================================\n\u9ad8\u65af\u8fc7\u7a0b\u5206\u7c7b\u5668(GPC)\u5728\u9e22\u5c3e\u82b1\u6570\u636e\u96c6\u4e0a\u7684\u5e94\u7528\n=====================================================\n\n\u8be5\u793a\u4f8b\u5c55\u793a\u4e86\u5728iris\u6570\u636e\u96c6\u7684\u4e8c\u7ef4\u7248\u672c\u4e0a \u5404\u5411\u540c\u6027\u548c\u5404\u5411\u5f02\u6027RBF\u6838\u7684GPC\u7684\u9884\u6d4b\u6982\u7387\u3002 \u8fd9\u8bf4\u660e\u4e86GPC\u5bf9\u591a\u7c7b\u5206\u7c7b\u7684\u9002\u7528\u6027\u3002 \n\u5404\u5411\u5f02\u6027RBF\u5185\u6838\u901a\u8fc7\u4e3a\u4e24\u4e2a\u7279\u5f81\u7ef4\u5ea6\u5206\u914d\u4e0d\u540c\u7684\u957f\u5ea6\u5c3a\u5ea6(length-scales)\u6765\u83b7\u5f97\u7a0d\u9ad8\u7684LML(log-marginal-likelihood)\u3002\n\n\u7ffb\u8bd1\u8005\uff1ahttp://www.studyai.com/antares\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(__doc__)\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn import datasets\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.gaussian_process.kernels import RBF\n\n# import some data to play with\niris = datasets.load_iris()\nX = iris.data[:, :2]  # we only take the first two features.\ny = np.array(iris.target, dtype=int)\n\nh = .02  # step size in the mesh\n\nkernel = 1.0 * RBF([1.0])\ngpc_rbf_isotropic = GaussianProcessClassifier(kernel=kernel).fit(X, y)\nkernel = 1.0 * RBF([1.0, 1.0])\ngpc_rbf_anisotropic = GaussianProcessClassifier(kernel=kernel).fit(X, y)\n\n# create a mesh to plot in\nx_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\ny_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\nxx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n                     np.arange(y_min, y_max, h))\n\ntitles = [\"Isotropic RBF\", \"Anisotropic RBF\"]\nplt.figure(figsize=(10, 5))\nfor i, clf in enumerate((gpc_rbf_isotropic, gpc_rbf_anisotropic)):\n    # Plot the predicted probabilities. For that, we will assign a color to\n    # each point in the mesh [x_min, m_max]x[y_min, y_max].\n    plt.subplot(1, 2, i + 1)\n\n    Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])\n\n    # Put the result into a color plot\n    Z = Z.reshape((xx.shape[0], xx.shape[1], 3))\n    plt.imshow(Z, extent=(x_min, x_max, y_min, y_max), origin=\"lower\")\n\n    # Plot also the training points\n    plt.scatter(X[:, 0], X[:, 1], c=np.array([\"r\", \"g\", \"b\"])[y],\n                edgecolors=(0, 0, 0))\n    plt.xlabel('Sepal length')\n    plt.ylabel('Sepal width')\n    plt.xlim(xx.min(), xx.max())\n    plt.ylim(yy.min(), yy.max())\n    plt.xticks(())\n    plt.yticks(())\n    plt.title(\"%s, LML: %.3f\" %\n              (titles[i], clf.log_marginal_likelihood(clf.kernel_.theta)))\n\nplt.tight_layout()\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}