{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n=============================================================\n\u5e26\u6709\u566a\u58f0\u6c34\u5e73\u4f30\u8ba1\u7684\u9ad8\u65af\u8fc7\u7a0b\u56de\u5f52(GPR)\n=============================================================\n\n\u8fd9\u4e2a\u4f8b\u5b50\u5c55\u793a\u4e86\u5e26\u6709sum-kernel\u7684GPR(\u5305\u62ecWhiteKernel)\u53ef\u4ee5\u4f30\u8ba1\u6570\u636e\u7684\u566a\u58f0\u6c34\u5e73\u3002\n\u5bf9\u6570\u8fb9\u7f18\u4f3c\u7136(LML)\u666f\u89c2\u56fe\u8868\u660e\uff1aLML\u5b58\u5728\u4e24\u4e2a\u5c40\u90e8\u6781\u5927\u503c.\n\u7b2c\u4e00\u4e2a\u56fe\u5bf9\u5e94\u4e8e\u4e00\u4e2a\u9ad8\u566a\u58f0\u6c34\u5e73\u548c\u5927\u957f\u5ea6\u5c3a\u5ea6\u7684\u6a21\u578b\uff0c\u5b83\u89e3\u91ca\u4e86\u566a\u58f0\u5e26\u7ed9\u6570\u636e\u7684\u6240\u6709\u53d8\u5316\u3002\n\u7b2c\u4e8c\u4e2a\u56fe\u5bf9\u5e94\u4e8e\u566a\u58f0\u6c34\u5e73\u8f83\u5c0f\uff0c\u957f\u5ea6\u5c3a\u5ea6\u8f83\u77ed\u7684\u6a21\u578b\uff0c\u4e3b\u8981\u89e3\u91ca\u4e86\u4e0e\u566a\u58f0\u65e0\u5173\u7684\u51fd\u6570\u5173\u7cfb\u5e26\u7ed9\u6570\u636e\u7684\u5927\u591a\u6570\u53d8\u5316\u3002\n\u7b2c\u4e8c\u4e2a\u6a21\u578b\u5177\u6709\u8f83\u9ad8\u7684likelihood\uff0c\u4f46\u662f\uff0c\u6839\u636e\u8d85\u53c2\u6570\u7684\u521d\u59cb\u503c\uff0c\u57fa\u4e8e\u68af\u5ea6\u7684\u4f18\u5316\u4e5f\u53ef\u80fd\u6536\u655b\u5230\u9ad8\u566a\u58f0\u7684\u89e3\u3002\n\u56e0\u6b64\uff0c\u4ee5\u4e0d\u540c\u7684\u521d\u59cb\u5316\u72b6\u6001\u8fdb\u884c\u591a\u6b21\u91cd\u590d\u4f18\u5316\u662f\u5f88\u91cd\u8981\u7684\u3002\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(__doc__)\n\n# Authors: Jan Hendrik Metzen <jhm@informatik.uni-bremen.de>\n# \u7ffb\u8bd1\u8005\uff1ahttp://www.studyai.com/antares\n# License: BSD 3 clause\n\nimport numpy as np\n\nfrom matplotlib import pyplot as plt\nfrom matplotlib.colors import LogNorm\n\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, WhiteKernel\n\n\nrng = np.random.RandomState(0)\nX = rng.uniform(0, 5, 20)[:, np.newaxis]\ny = 0.5 * np.sin(3 * X[:, 0]) + rng.normal(0, 0.5, X.shape[0])\n\n# First run\nplt.figure(0)\nkernel = 1.0 * RBF(length_scale=100.0, length_scale_bounds=(1e-2, 1e3)) \\\n    + WhiteKernel(noise_level=1, noise_level_bounds=(1e-10, 1e+1))\ngp = GaussianProcessRegressor(kernel=kernel,\n                              alpha=0.0).fit(X, y)\nX_ = np.linspace(0, 5, 100)\ny_mean, y_cov = gp.predict(X_[:, np.newaxis], return_cov=True)\nplt.plot(X_, y_mean, 'k', lw=3, zorder=9)\nplt.fill_between(X_, y_mean - np.sqrt(np.diag(y_cov)),\n                 y_mean + np.sqrt(np.diag(y_cov)),\n                 alpha=0.5, color='k')\nplt.plot(X_, 0.5*np.sin(3*X_), 'r', lw=3, zorder=9)\nplt.scatter(X[:, 0], y, c='r', s=50, zorder=10, edgecolors=(0, 0, 0))\nplt.title(\"Initial: %s\\nOptimum: %s\\nLog-Marginal-Likelihood: %s\"\n          % (kernel, gp.kernel_,\n             gp.log_marginal_likelihood(gp.kernel_.theta)))\nplt.tight_layout()\n\n# Second run\nplt.figure(1)\nkernel = 1.0 * RBF(length_scale=1.0, length_scale_bounds=(1e-2, 1e3)) \\\n    + WhiteKernel(noise_level=1e-5, noise_level_bounds=(1e-10, 1e+1))\ngp = GaussianProcessRegressor(kernel=kernel,\n                              alpha=0.0).fit(X, y)\nX_ = np.linspace(0, 5, 100)\ny_mean, y_cov = gp.predict(X_[:, np.newaxis], return_cov=True)\nplt.plot(X_, y_mean, 'k', lw=3, zorder=9)\nplt.fill_between(X_, y_mean - np.sqrt(np.diag(y_cov)),\n                 y_mean + np.sqrt(np.diag(y_cov)),\n                 alpha=0.5, color='k')\nplt.plot(X_, 0.5*np.sin(3*X_), 'r', lw=3, zorder=9)\nplt.scatter(X[:, 0], y, c='r', s=50, zorder=10, edgecolors=(0, 0, 0))\nplt.title(\"Initial: %s\\nOptimum: %s\\nLog-Marginal-Likelihood: %s\"\n          % (kernel, gp.kernel_,\n             gp.log_marginal_likelihood(gp.kernel_.theta)))\nplt.tight_layout()\n\n# Plot LML landscape\nplt.figure(2)\ntheta0 = np.logspace(-2, 3, 49)\ntheta1 = np.logspace(-2, 0, 50)\nTheta0, Theta1 = np.meshgrid(theta0, theta1)\nLML = [[gp.log_marginal_likelihood(np.log([0.36, Theta0[i, j], Theta1[i, j]]))\n        for i in range(Theta0.shape[0])] for j in range(Theta0.shape[1])]\nLML = np.array(LML).T\n\nvmin, vmax = (-LML).min(), (-LML).max()\nvmax = 50\nlevel = np.around(np.logspace(np.log10(vmin), np.log10(vmax), 50), decimals=1)\nplt.contour(Theta0, Theta1, -LML,\n            levels=level, norm=LogNorm(vmin=vmin, vmax=vmax))\nplt.colorbar()\nplt.xscale(\"log\")\nplt.yscale(\"log\")\nplt.xlabel(\"Length-scale\")\nplt.ylabel(\"Noise-level\")\nplt.title(\"Log-marginal-likelihood\")\nplt.tight_layout()\n\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}