{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n=========================================================\n\u9ad8\u65af\u8fc7\u7a0b\u56de\u5f52: \u57fa\u672c\u7684\u4ecb\u7ecd\u6027\u6848\u4f8b\n=========================================================\n\n\u4e00\u4e2a\u7b80\u5355\u7684\u4e00\u7ef4\u56de\u5f52\u4f8b\u5b50\uff0c\u4ee5\u4e24\u79cd\u4e0d\u540c\u7684\u65b9\u5f0f\u8ba1\u7b97\uff1a\n\n1. \u6ca1\u6709\u566a\u58f0\u7684\u60c5\u51b5\n2. \u6bcf\u4e2a\u6570\u636e\u70b9\u7684\u566a\u58f0\u6c34\u5e73\u5df2\u77e5\u7684\u6709\u566a\u58f0\u60c5\u51b5\n\n\u5728\u4e0a\u8ff0\u4e24\u79cd\u60c5\u51b5\u4e0b, \u5185\u6838\u53c2\u6570\u53ef\u4ee5\u4f7f\u7528\u6700\u5927\u4f3c\u7136\u539f\u5219\u88ab\u4f30\u8ba1\u51fa\u6765\u3002\n\n\u5b9e\u9a8c\u56fe\u50cf\u5c55\u793a\u4e86\u9ad8\u65af\u8fc7\u7a0b\u6a21\u578b\u7684\u5185\u63d2\u7279\u6027(interpolating property)\u4ee5\u53ca\n\u5b83\u7684\u6982\u7387\u6027\u672c\u8d28\uff1a\u4e3a\u6bcf\u4e2a\u70b9\u7684\u9884\u6d4b\u7ed3\u679c\u7ed9\u51fa95%\u7684\u7f6e\u4fe1\u533a\u95f4\u3002\n\nNote that the parameter ``alpha`` is applied as a Tikhonov\nregularization of the assumed covariance between the training points.\n\u6ce8\u610f\uff0c\u53c2\u6570 ``alpha`` \u88ab\u7528\u505a\u8bad\u7ec3\u70b9\u4e4b\u95f4\u5047\u8bbe\u534f\u65b9\u5dee\u7684Tikhonov\u6b63\u5219\u5316\u3002\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(__doc__)\n\n# Author: Vincent Dubourg <vincent.dubourg@gmail.com>\n#         Jake Vanderplas <vanderplas@astro.washington.edu>\n#         Jan Hendrik Metzen <jhm@informatik.uni-bremen.de>s\n# \u7ffb\u8bd1\u8005\uff1awww.studyai.com/antares\n# License: BSD 3 clause\n\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n\nnp.random.seed(1)\n\n\ndef f(x):\n    \"\"\"The function to predict.\"\"\"\n    return x * np.sin(x)\n\n# ----------------------------------------------------------------------\n#  First the noiseless case\nX = np.atleast_2d([1., 3., 5., 6., 7., 8.]).T\n\n# Observations\ny = f(X).ravel()\n\n# Mesh the input space for evaluations of the real function, the prediction and\n# its MSE\nx = np.atleast_2d(np.linspace(0, 10, 1000)).T\n\n# Instantiate a Gaussian Process model\nkernel = C(1.0, (1e-3, 1e3)) * RBF(10, (1e-2, 1e2))\ngp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=9)\n\n# Fit to data using Maximum Likelihood Estimation of the parameters\ngp.fit(X, y)\n\n# Make the prediction on the meshed x-axis (ask for MSE as well)\ny_pred, sigma = gp.predict(x, return_std=True)\n\n# Plot the function, the prediction and the 95% confidence interval based on\n# the MSE\nplt.figure()\nplt.plot(x, f(x), 'r:', label=u'$f(x) = x\\,\\sin(x)$')\nplt.plot(X, y, 'r.', markersize=10, label=u'Observations')\nplt.plot(x, y_pred, 'b-', label=u'Prediction')\nplt.fill(np.concatenate([x, x[::-1]]),\n         np.concatenate([y_pred - 1.9600 * sigma,\n                        (y_pred + 1.9600 * sigma)[::-1]]),\n         alpha=.5, fc='b', ec='None', label='95% confidence interval')\nplt.xlabel('$x$')\nplt.ylabel('$f(x)$')\nplt.ylim(-10, 20)\nplt.legend(loc='upper left')\n\n# ----------------------------------------------------------------------\n# now the noisy case\nX = np.linspace(0.1, 9.9, 20)\nX = np.atleast_2d(X).T\n\n# Observations and noise\ny = f(X).ravel()\ndy = 0.5 + 1.0 * np.random.random(y.shape)\nnoise = np.random.normal(0, dy)\ny += noise\n\n# Instantiate a Gaussian Process model\ngp = GaussianProcessRegressor(kernel=kernel, alpha=dy ** 2,\n                              n_restarts_optimizer=10)\n\n# Fit to data using Maximum Likelihood Estimation of the parameters\ngp.fit(X, y)\n\n# Make the prediction on the meshed x-axis (ask for MSE as well)\ny_pred, sigma = gp.predict(x, return_std=True)\n\n# Plot the function, the prediction and the 95% confidence interval based on\n# the MSE\nplt.figure()\nplt.plot(x, f(x), 'r:', label=u'$f(x) = x\\,\\sin(x)$')\nplt.errorbar(X.ravel(), y, dy, fmt='r.', markersize=10, label=u'Observations')\nplt.plot(x, y_pred, 'b-', label=u'Prediction')\nplt.fill(np.concatenate([x, x[::-1]]),\n         np.concatenate([y_pred - 1.9600 * sigma,\n                        (y_pred + 1.9600 * sigma)[::-1]]),\n         alpha=.5, fc='b', ec='None', label='95% confidence interval')\nplt.xlabel('$x$')\nplt.ylabel('$f(x)$')\nplt.ylim(-10, 20)\nplt.legend(loc='upper left')\n\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}