{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n=============================================\n\u6838\u5cad\u56de\u5f52(KRR)\u4e0e\u652f\u6301\u5411\u91cf\u56de\u5f52(SVR)\u7684\u6bd4\u8f83\n=============================================\n\n\u6838\u5cad\u56de\u5f52(KRR)\u4e0e\u652f\u6301\u5411\u91cf\u56de\u5f52(SVR)\u90fd\u53ef\u4ee5\u5229\u7528\u6838\u6280\u5de7\u6765\u5b66\u4e60\u975e\u7ebf\u6027\u51fd\u6570\uff0c\u4e5f\u5c31\u662f\u8bf4, \n\u5b83\u4eec\u53ef\u4ee5\u5728\u76f8\u5e94\u7684\u6838\u8bf1\u5bfc\u51fa\u7684\u7a7a\u95f4\u4e2d\u5b66\u4e60\u4e00\u4e2a\u7ebf\u6027\u51fd\u6570\u3002\u800c\u8be5\u6838\u8bf1\u5bfc\u7a7a\u95f4\u7684\u7ebf\u6027\u51fd\u6570\u5bf9\u5e94\u4e8e\u539f\u59cb\u7a7a\u95f4\u7684\u975e\u7ebf\u6027\u51fd\u6570\u3002\n\u5b83\u4eec\u7684\u533a\u522b\u5728\u4e8e\u635f\u5931\u51fd\u6570(ridge versus epsilon-insensitive loss)\u3002\n\u4e0eSVR\u76f8\u6bd4\u8f83, KRR\u7684\u62df\u5408\u53ef\u4ee5\u7528\u95ed\u5408\u5f62\u5f0f(closed-form)\u5b8c\u6210\uff0c\u5e76\u4e14\u5728\u4e2d\u7b49\u89c4\u6a21\u7684\u6570\u636e\u96c6\u4e0a\u901a\u5e38\u66f4\u5feb\u3002\n\u53e6\u4e00\u65b9\u9762\uff0cKRR\u5b66\u4e60\u5230\u7684\u6a21\u578b\u662f\u975e\u7a00\u758f\u7684\uff0c\u6240\u4ee5\u5728\u9884\u6d4b\u9636\u6bb5KRR\u6bd4SVR\u8981\u6162\u3002\n\n\u4e0b\u9762\u8fd9\u4e2a\u6848\u4f8b\u5c55\u793a\u4e86\u5c06\u8fd9\u4e24\u4e2a\u65b9\u6cd5\u7528\u4e8e\u4eba\u5de5\u6570\u636e\u96c6\uff0c\u5b83\u7531\u4e00\u4e2a\u6b63\u5f26\u76ee\u6807\u51fd\u6570\u548c\u6bcf\u4e94\u4e2a\u6570\u636e\u70b9\u6240\u52a0\u7684\u5f3a\u566a\u58f0\u7ec4\u6210\u3002\n\u7b2c\u4e00\u4e2a\u56fe\u6bd4\u8f83\u4e86\u5728\u4f7f\u7528\u7f51\u683c\u641c\u7d22\u4f18\u5316\u4e86RBF\u6838\u7684\u6b63\u5219\u5316\u548c\u5e26\u5bbd\u65f6\uff0cKRR\u548cSVR\u5b66\u4e60\u5230\u7684\u6a21\u578b\u3002\u5b83\u4eec\u5b66\u4e60\u5230\u7684\u51fd\u6570\u662f\u975e\u5e38\u76f8\u4f3c\u7684\uff0c\n\u4f46\u662f\uff0c\u62df\u5408KRR\u5927\u7ea6\u6bd4\u62df\u5408SVR\u5feb7\u500d(\u90fd\u4f7f\u7528\u4e86\u7f51\u683c\u641c\u7d22)\u3002\n\u7136\u800c\uff0c\u4f7f\u7528SVR\u9884\u6d4b100000\u4e2a\u76ee\u6807\u503c\u8981\u6bd4KRR\u5feb\u4e09\u500d\uff0c\u56e0\u4e3a\u5b83\u53ea\u4f7f\u7528\u4e86100\u9879\u8bad\u7ec3\u6570\u636e\u4e2d\u7684\u5927\u7ea61/3\u4f5c\u4e3a\u652f\u6301\u5411\u91cf\u5c31\u5b66\u5230\u4e86\u7a00\u758f\u6a21\u578b\u3002\n\n\u4e0b\u4e00\u4e2a\u56fe\u6bd4\u8f83\u4e86\u5728\u4e0d\u540c\u8bad\u7ec3\u96c6\u4e0aKRR\u548cSVR\u7684\u62df\u5408\u548c\u9884\u6d4b\u65f6\u95f4\u3002\u5bf9\u4e8e\u4e2d\u7b49\u89c4\u6a21\u7684\u8bad\u7ec3\u96c6(\u5c0f\u4e8e1000\u4e2a\u6837\u672c)\uff0c\u62df\u5408KRR\u6bd4SVR\u66f4\u5feb\uff1b\n\u7136\u800c\uff0c\u5bf9\u4e8e\u8f83\u5927\u7684\u8bad\u7ec3\u96c6\uff0cSVR\u7684\u65f6\u95f4\u5f39\u6027\u66f4\u597d\u3002\u5728\u9884\u6d4b\u65f6\u95f4\u65b9\u9762\uff0c\u7531\u4e8e\u5b66\u4e60\u5230\u7684\u7a00\u758f\u89e3\uff0cSVR\u5bf9\u4e8e\u6240\u6709\u8bad\u7ec3\u96c6\u7684\u5927\u5c0f\u90fd\u6bd4KRR\u66f4\u5feb\u3002\n\u8bf7\u6ce8\u610f\uff0c\u7a00\u758f\u5ea6\u548c\u9884\u6d4b\u65f6\u95f4\u53d6\u51b3\u4e8eSVR\u7684\u53c2\u6570epsilon\u548cC\u3002\n\n\u7ffb\u8bd1\u8005\uff1a http://www.studyai.com/antares\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Jan Hendrik Metzen <jhm@informatik.uni-bremen.de>\n# License: BSD 3 clause\n\n\nfrom __future__ import division\nimport time\n\nimport numpy as np\n\nfrom sklearn.svm import SVR\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.kernel_ridge import KernelRidge\nimport matplotlib.pyplot as plt\n\nrng = np.random.RandomState(0)\n\n# #############################################################################\n# Generate sample data\nX = 5 * rng.rand(10000, 1)\ny = np.sin(X).ravel()\n\n# Add noise to targets\ny[::5] += 3 * (0.5 - rng.rand(X.shape[0] // 5))\n\nX_plot = np.linspace(0, 5, 100000)[:, None]\n\n# #############################################################################\n# Fit regression model\ntrain_size = 100\nsvr = GridSearchCV(SVR(kernel='rbf', gamma=0.1), cv=5,\n                   param_grid={\"C\": [1e0, 1e1, 1e2, 1e3],\n                               \"gamma\": np.logspace(-2, 2, 5)})\n\nkr = GridSearchCV(KernelRidge(kernel='rbf', gamma=0.1), cv=5,\n                  param_grid={\"alpha\": [1e0, 0.1, 1e-2, 1e-3],\n                              \"gamma\": np.logspace(-2, 2, 5)})\n\nt0 = time.time()\nsvr.fit(X[:train_size], y[:train_size])\nsvr_fit = time.time() - t0\nprint(\"SVR complexity and bandwidth selected and model fitted in %.3f s\"\n      % svr_fit)\n\nt0 = time.time()\nkr.fit(X[:train_size], y[:train_size])\nkr_fit = time.time() - t0\nprint(\"KRR complexity and bandwidth selected and model fitted in %.3f s\"\n      % kr_fit)\n\nsv_ratio = svr.best_estimator_.support_.shape[0] / train_size\nprint(\"Support vector ratio: %.3f\" % sv_ratio)\n\nt0 = time.time()\ny_svr = svr.predict(X_plot)\nsvr_predict = time.time() - t0\nprint(\"SVR prediction for %d inputs in %.3f s\"\n      % (X_plot.shape[0], svr_predict))\n\nt0 = time.time()\ny_kr = kr.predict(X_plot)\nkr_predict = time.time() - t0\nprint(\"KRR prediction for %d inputs in %.3f s\"\n      % (X_plot.shape[0], kr_predict))\n\n\n# #############################################################################\n# Look at the results\nsv_ind = svr.best_estimator_.support_\nplt.scatter(X[sv_ind], y[sv_ind], c='r', s=50, label='SVR support vectors',\n            zorder=2, edgecolors=(0, 0, 0))\nplt.scatter(X[:100], y[:100], c='k', label='data', zorder=1,\n            edgecolors=(0, 0, 0))\nplt.plot(X_plot, y_svr, c='r',\n         label='SVR (fit: %.3fs, predict: %.3fs)' % (svr_fit, svr_predict))\nplt.plot(X_plot, y_kr, c='g',\n         label='KRR (fit: %.3fs, predict: %.3fs)' % (kr_fit, kr_predict))\nplt.xlabel('data')\nplt.ylabel('target')\nplt.title('SVR versus Kernel Ridge')\nplt.legend()\n\n# Visualize training and prediction time\nplt.figure()\n\n# Generate sample data\nX = 5 * rng.rand(10000, 1)\ny = np.sin(X).ravel()\ny[::5] += 3 * (0.5 - rng.rand(X.shape[0] // 5))\nsizes = np.logspace(1, 4, 7).astype(np.int)\nfor name, estimator in {\"KRR\": KernelRidge(kernel='rbf', alpha=0.1,\n                                           gamma=10),\n                        \"SVR\": SVR(kernel='rbf', C=1e1, gamma=10)}.items():\n    train_time = []\n    test_time = []\n    for train_test_size in sizes:\n        t0 = time.time()\n        estimator.fit(X[:train_test_size], y[:train_test_size])\n        train_time.append(time.time() - t0)\n\n        t0 = time.time()\n        estimator.predict(X_plot[:1000])\n        test_time.append(time.time() - t0)\n\n    plt.plot(sizes, train_time, 'o-', color=\"r\" if name == \"SVR\" else \"g\",\n             label=\"%s (train)\" % name)\n    plt.plot(sizes, test_time, 'o--', color=\"r\" if name == \"SVR\" else \"g\",\n             label=\"%s (test)\" % name)\n\nplt.xscale(\"log\")\nplt.yscale(\"log\")\nplt.xlabel(\"Train size\")\nplt.ylabel(\"Time (seconds)\")\nplt.title('Execution Time')\nplt.legend(loc=\"best\")\n\n# Visualize learning curves\nplt.figure()\n\nsvr = SVR(kernel='rbf', C=1e1, gamma=0.1)\nkr = KernelRidge(kernel='rbf', alpha=0.1, gamma=0.1)\ntrain_sizes, train_scores_svr, test_scores_svr = \\\n    learning_curve(svr, X[:100], y[:100], train_sizes=np.linspace(0.1, 1, 10),\n                   scoring=\"neg_mean_squared_error\", cv=10)\ntrain_sizes_abs, train_scores_kr, test_scores_kr = \\\n    learning_curve(kr, X[:100], y[:100], train_sizes=np.linspace(0.1, 1, 10),\n                   scoring=\"neg_mean_squared_error\", cv=10)\n\nplt.plot(train_sizes, -test_scores_svr.mean(1), 'o-', color=\"r\",\n         label=\"SVR\")\nplt.plot(train_sizes, -test_scores_kr.mean(1), 'o-', color=\"g\",\n         label=\"KRR\")\nplt.xlabel(\"Train size\")\nplt.ylabel(\"Mean Squared Error\")\nplt.title('Learning curves')\nplt.legend(loc=\"best\")\n\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}