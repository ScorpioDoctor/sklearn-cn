{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n=================================================\nSVM: \u4e0d\u5e73\u8861\u5206\u7c7b\u95ee\u9898\u7684\u5206\u5272\u8d85\u5e73\u9762\n=================================================\n\n\u4f7f\u7528SVC\u5bfb\u627e\u4e0d\u5e73\u8861\u5206\u7c7b\u95ee\u9898\u7684\u6700\u4f18\u5206\u5272\u8d85\u5e73\u9762\n\n\u6211\u4eec\u9996\u5148\u4f7f\u7528\u4e00\u4e2a\u7b80\u5355\u7684SVC\u627e\u5230\u5206\u5272\u8d85\u5e73\u9762\uff0c\u7136\u540e(\u7528\u865a\u7ebf)\u753b\u51fa\u5206\u79bb\u8d85\u5e73\u9762,\u5bf9\u90a3\u4e9b\u4e0d\u5e73\u8861\u7c7b\u522b\u8fdb\u884c\u81ea\u52a8\u77eb\u6b63\u3002\n\n.. currentmodule:: sklearn.linear_model\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>\u4f7f\u7528 ``SGDClassifier(loss=\"hinge\")`` \u66ff\u6362 ``SVC(kernel=\"linear\")`` \u4ee5\u540e\uff0c\n    \u8fd9\u4e2a\u4f8b\u5b50\u4ecd\u7136\u53ef\u4ee5\u5de5\u4f5c\u3002 \u8bbe\u7f6e :class:`SGDClassifier`  \u7c7b\u7684 ``loss`` \u53c2\u6570\n    \u4e3a ``hinge`` \u5c06\u4ea7\u751f\u4e0e\u5e26\u6709\u7ebf\u6027\u6838\u7684SVC\u4e00\u6837\u7684\u884c\u4e3a\u3002\n\n    \u6bd4\u5982\u5c1d\u8bd5\u7528\u4e0b\u9762\u7684\u4f30\u8ba1\u5668\u5b9e\u4f8b\u66ff\u6362 ``SVC``::\n\n        clf = SGDClassifier(n_iter=100, alpha=0.01)</p></div>\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(__doc__)\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn import svm\nfrom sklearn.datasets import make_blobs\n\n# we create two clusters of random points\nn_samples_1 = 1000\nn_samples_2 = 100\ncenters = [[0.0, 0.0], [2.0, 2.0]]\nclusters_std = [1.5, 0.5]\nX, y = make_blobs(n_samples=[n_samples_1, n_samples_2],\n                  centers=centers,\n                  cluster_std=clusters_std,\n                  random_state=0, shuffle=False)\n\n# fit the model and get the separating hyperplane\nclf = svm.SVC(kernel='linear', C=1.0)\nclf.fit(X, y)\n\n# fit the model and get the separating hyperplane using weighted classes\nwclf = svm.SVC(kernel='linear', class_weight={1: 10})\nwclf.fit(X, y)\n\n# plot the samples\nplt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Paired, edgecolors='k')\n\n# plot the decision functions for both classifiers\nax = plt.gca()\nxlim = ax.get_xlim()\nylim = ax.get_ylim()\n\n# create grid to evaluate model\nxx = np.linspace(xlim[0], xlim[1], 30)\nyy = np.linspace(ylim[0], ylim[1], 30)\nYY, XX = np.meshgrid(yy, xx)\nxy = np.vstack([XX.ravel(), YY.ravel()]).T\n\n# get the separating hyperplane\nZ = clf.decision_function(xy).reshape(XX.shape)\n\n# plot decision boundary and margins\na = ax.contour(XX, YY, Z, colors='k', levels=[0], alpha=0.5, linestyles=['-'])\n\n# get the separating hyperplane for weighted classes\nZ = wclf.decision_function(xy).reshape(XX.shape)\n\n# plot decision boundary and margins for weighted classes\nb = ax.contour(XX, YY, Z, colors='r', levels=[0], alpha=0.5, linestyles=['-'])\n\nplt.legend([a.collections[0], b.collections[0]], [\"non weighted\", \"weighted\"],\n           loc=\"upper right\")\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}